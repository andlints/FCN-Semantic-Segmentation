{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traitement des données d'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_data = '../dataset1/'\n",
    "dir_seg = dir_data + \"annotations_prepped_train/\"\n",
    "dir_img = dir_data + \"images_prepped_train/\"\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldseg = np.array(os.listdir(dir_seg))\n",
    "fnm = ldseg[0]\n",
    "seg = cv2.imread(dir_seg + fnm ) # (360, 480, 3)\n",
    "img_is = cv2.imread(dir_img + fnm )\n",
    "mi, ma = np.min(seg), np.max(seg)\n",
    "n_classes = ma - mi + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_color_to_seg_img(seg,n_classes):\n",
    "    \n",
    "    if len(seg.shape)==3:\n",
    "        seg = seg[:,:,0]\n",
    "    seg_img = np.zeros( (seg.shape[0],seg.shape[1],3) ).astype('float')\n",
    "    colors = sns.color_palette(\"hls\", n_classes)\n",
    "    \n",
    "    for c in range(n_classes):\n",
    "        segc = (seg == c)\n",
    "        seg_img[:,:,0] += (segc*( colors[c][0] ))\n",
    "        seg_img[:,:,1] += (segc*( colors[c][1] ))\n",
    "        seg_img[:,:,2] += (segc*( colors[c][2] ))\n",
    "\n",
    "    return(seg_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_height , input_width = 224 , 224\n",
    "output_height , output_width = 224 , 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldseg = np.array(os.listdir(dir_seg))\n",
    "for fnm in ldseg[np.random.choice(len(ldseg),3,replace=False)]:\n",
    "    fnm = fnm.split(\".\")[0]\n",
    "    seg = cv2.imread(dir_seg + fnm + \".png\") # (360, 480, 3)\n",
    "    img_is = cv2.imread(dir_img + fnm + \".png\")\n",
    "    seg_img = give_color_to_seg_img(seg,n_classes)\n",
    "\n",
    "def getImageArr( path , width , height ):\n",
    "        img = cv2.imread(path, 1)\n",
    "        img = np.float32(cv2.resize(img, ( width , height ))) / 127.5 - 1\n",
    "        return img\n",
    "\n",
    "def getSegmentationArr( path , nClasses ,  width , height  ):\n",
    "\n",
    "    seg_labels = np.zeros((  height , width  , nClasses ))\n",
    "    img = cv2.imread(path, 1)\n",
    "    img = cv2.resize(img, ( width , height ))\n",
    "    img = img[:, : , 0]\n",
    "\n",
    "    for c in range(nClasses):\n",
    "        seg_labels[: , : , c ] = (img == c ).astype(int)\n",
    "    return seg_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = os.listdir(dir_img)\n",
    "images.sort()\n",
    "segmentations  = os.listdir(dir_seg)\n",
    "segmentations.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "for im , seg in zip(images,segmentations) :\n",
    "    X.append( getImageArr(dir_img + im , input_width , input_height )  )\n",
    "    Y.append( getSegmentationArr( dir_seg + seg , n_classes , output_width , output_height )  )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = np.array(X) , np.array(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création FCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "import keras, sys, time, warnings\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "import pandas as pd \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\" \n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.95\n",
    "config.gpu_options.visible_device_list = \"2\" \n",
    "tf.compat.v1.keras.backend.set_session(tf.compat.v1.Session(config=config))   \n",
    "\n",
    "VGG_Weights_path = \"vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\" \n",
    "# les poids\n",
    "# transfer learning\n",
    "# on appelle des poids d'un modele deja entrainner qui est le VGG\n",
    "# pour entrainner notre modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VGG_Weights_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FCN8( nClasses ,  input_height=224, input_width=224):\n",
    "    assert input_height%32 == 0\n",
    "    assert input_width%32 == 0\n",
    "    IMAGE_ORDERING =  \"channels_last\" \n",
    "\n",
    "    img_input = Input(shape=(input_height,input_width, 3)) ## Assume 224,224,3\n",
    "    \n",
    "    ## Block 1\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1', data_format=IMAGE_ORDERING )(img_input)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2', data_format=IMAGE_ORDERING )(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool', data_format=IMAGE_ORDERING )(x)\n",
    "    f1 = x\n",
    "    \n",
    "    # Block 2\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1', data_format=IMAGE_ORDERING )(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2', data_format=IMAGE_ORDERING )(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool', data_format=IMAGE_ORDERING )(x)\n",
    "    f2 = x\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1', data_format=IMAGE_ORDERING )(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2', data_format=IMAGE_ORDERING )(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3', data_format=IMAGE_ORDERING )(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool', data_format=IMAGE_ORDERING )(x)\n",
    "    pool3 = x\n",
    "\n",
    "    # Block 4\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1', data_format=IMAGE_ORDERING )(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2', data_format=IMAGE_ORDERING )(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3', data_format=IMAGE_ORDERING )(x)\n",
    "    pool4 = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool', data_format=IMAGE_ORDERING )(x)## (None, 14, 14, 512) \n",
    "\n",
    "    # Block 5\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1', data_format=IMAGE_ORDERING )(pool4)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2', data_format=IMAGE_ORDERING )(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3', data_format=IMAGE_ORDERING )(x)\n",
    "    pool5 = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool', data_format=IMAGE_ORDERING )(x)## (None, 7, 7, 512)\n",
    "\n",
    "    \n",
    "    vgg  = Model(  img_input , pool5  )\n",
    "    vgg.load_weights(VGG_Weights_path) \n",
    "    \n",
    "    n = 4096\n",
    "    o = ( Conv2D( n , ( 7 , 7 ) , activation='relu' , padding='same', name=\"conv6\", data_format=IMAGE_ORDERING))(pool5)\n",
    "    conv7 = ( Conv2D( n , ( 1 , 1 ) , activation='relu' , padding='same', name=\"conv7\", data_format=IMAGE_ORDERING))(o)\n",
    "    conv7_4 = Conv2DTranspose( nClasses , kernel_size=(4,4) ,  strides=(4,4) , use_bias=False, data_format=IMAGE_ORDERING )(conv7)\n",
    "    pool411 = ( Conv2D( nClasses , ( 1 , 1 ) , activation='relu' , padding='same', name=\"pool4_11\", data_format=IMAGE_ORDERING))(pool4)\n",
    "    pool411_2 = (Conv2DTranspose( nClasses , kernel_size=(2,2) ,  strides=(2,2) , use_bias=False, data_format=IMAGE_ORDERING ))(pool411)\n",
    "    pool311 = ( Conv2D( nClasses , ( 1 , 1 ) , activation='relu' , padding='same', name=\"pool3_11\", data_format=IMAGE_ORDERING))(pool3)\n",
    "        \n",
    "    o = Add(name=\"add\")([pool411_2, pool311, conv7_4 ])\n",
    "    o = Conv2DTranspose( nClasses , kernel_size=(8,8) ,  strides=(8,8) , use_bias=False, data_format=IMAGE_ORDERING )(o)\n",
    "    o = (Activation('softmax'))(o)\n",
    "    model = Model(img_input, o)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 224, 224, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 224, 224, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 112, 112, 64) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 112, 112, 128 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 112, 112, 128 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 56, 56, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 28, 28, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 14, 14, 512)  0           block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)      (None, 7, 7, 512)    0           block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv6 (Conv2D)                  (None, 7, 7, 4096)   102764544   block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "pool4_11 (Conv2D)               (None, 14, 14, 12)   6156        block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv7 (Conv2D)                  (None, 7, 7, 4096)   16781312    conv6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 28, 28, 12)   576         pool4_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool3_11 (Conv2D)               (None, 28, 28, 12)   3084        block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 28, 28, 12)   786432      conv7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 28, 28, 12)   0           conv2d_transpose_2[0][0]         \n",
      "                                                                 pool3_11[0][0]                   \n",
      "                                                                 conv2d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 224, 224, 12) 9216        add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 224, 224, 12) 0           conv2d_transpose_3[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 135,066,008\n",
      "Trainable params: 135,066,008\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = FCN8(n_classes, 224, 224)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[:200]\n",
    "Y = Y[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rate = 0.85\n",
    "index_train = np.random.choice(X.shape[0],int(X.shape[0]*train_rate),replace=False)\n",
    "index_test  = list(set(range(X.shape[0])) - set(index_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = shuffle(X,Y)\n",
    "X_train, y_train = X[index_train],Y[index_train]\n",
    "X_test, y_test = X[index_test],Y[index_test]\n",
    "#print(X_train.shape, y_train.shape)\n",
    "#print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 170 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "170/170 [==============================] - 1028s 6s/step - loss: 1.9977 - accuracy: 0.3105 - val_loss: 1.4790 - val_accuracy: 0.5622\n",
      "Epoch 2/10\n",
      "170/170 [==============================] - 717s 4s/step - loss: 1.1261 - accuracy: 0.6290 - val_loss: 0.9451 - val_accuracy: 0.7064\n",
      "Epoch 3/10\n",
      "170/170 [==============================] - 674s 4s/step - loss: 0.8657 - accuracy: 0.7327 - val_loss: 0.8556 - val_accuracy: 0.7330\n",
      "Epoch 4/10\n",
      "170/170 [==============================] - 669s 4s/step - loss: 0.7707 - accuracy: 0.7655 - val_loss: 0.8382 - val_accuracy: 0.7475\n",
      "Epoch 5/10\n",
      "170/170 [==============================] - 663s 4s/step - loss: 0.7025 - accuracy: 0.7871 - val_loss: 0.7929 - val_accuracy: 0.7508\n",
      "Epoch 6/10\n",
      "170/170 [==============================] - 684s 4s/step - loss: 0.6587 - accuracy: 0.8046 - val_loss: 0.7339 - val_accuracy: 0.7760\n",
      "Epoch 7/10\n",
      " 94/170 [===============>..............] - ETA: 5:53 - loss: 0.6436 - accuracy: 0.8099 ETA: 5:48 - loss: 0.6412 - accuracy: "
     ]
    }
   ],
   "source": [
    "sgd = optimizers.SGD(lr=1E-2, decay=5**(-4), momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "hist1 = model.fit(X_train,y_train,\n",
    "                  validation_data=(X_test,y_test),\n",
    "                  batch_size=1,epochs=10,verbose=1)\n",
    "\n",
    "\n",
    "for key in ['loss', 'val_loss']:\n",
    "    plt.plot(hist1.history[key],label=key)\n",
    "    \n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('DL_Loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model enregistré\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.save('TP_Deep_learning_200.h5')  \n",
    "print(\"Model enregistré\")   \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
